{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeboXjDlxHMa"
   },
   "source": [
    "ENTRENAMIENTO CON OCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBuYJLBdxH1h",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modelos_TL.load_data import load_data\n",
    "import tensorflow as tf\n",
    "\n",
    "base_dir='efs2/OCT2017'     #poner path de OCT2017\n",
    "model_name= 'Xception'\n",
    "IMG_SIZE = (150, 150)\n",
    "#train_dataset, test_dataset, validation_dataset, class_names= load_data(base_dir, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEMYI9dCxiof"
   },
   "source": [
    "## Crear el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srM-nfFt0e0e"
   },
   "outputs": [],
   "source": [
    "from Modelos_TL.make_model import modelo\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ENTRENAMIENTO CON OCT PARA METODOLOGIAS 2 Y 4\n",
    "# Xception\n",
    "\n",
    "IMG_SIZE = (150, 150)\n",
    "metrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "           tf.keras.metrics.FalsePositives(name='fp'),\n",
    "           tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "           tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "           tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "           tf.keras.metrics.Precision(name='precision'),\n",
    "           tf.keras.metrics.Recall(name='recall'),\n",
    "           tf.keras.metrics.AUC(name='auc'),\n",
    "           tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "           ]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjrZ30426Fl4",
    "outputId": "c01c9006-c07f-4666-87eb-7af3d4775f39"
   },
   "outputs": [],
   "source": [
    "model, base_model = modelo(IMG_SIZE, 'Xception', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, validation_dataset, class_names= load_data(base_dir, IMG_SIZE)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMWGK1fxoDe",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaKYA_Ay1LuC"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"efs/Checkpoints Xception/Entrenamiento con OCT/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XJsMJw5xtg4"
   },
   "source": [
    "## Congelo el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "FLI_CSs8-c6x",
    "outputId": "b5054cce-4220-4edb-eae9-0981e36d8d68"
   },
   "outputs": [],
   "source": [
    "from Modelos_TL.Train_model import train, fine_tunning\n",
    "base_model.trainable=False\n",
    "print(len(model.trainable_variables))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7S9dykbx_i3",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Entrenamiento capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuG3QzoW1MZz",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [],
   "source": [
    "history = train(model, base_dir, epoch=15, cp_callback=cp_callback, IMG_SIZE=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "#model.load_weights(checkpoint_path)\n",
    "import pandas as pd\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'history.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXBZrG9SyalA",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Visualizar metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj7TlozhyEtI"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "fine_tunning=False\n",
    "history_fine=None\n",
    "BATCH_SIZE=32\n",
    "baseline_results = model.evaluate(test_dataset,\n",
    "                                  batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "\n",
    "\n",
    "image_batch_train, train_labels = next(iter(train_dataset))\n",
    "image_batch_test, test_labels = next(iter(test_dataset))\n",
    "\n",
    "train_predictions = model.predict(image_batch_train, batch_size=BATCH_SIZE)\n",
    "test_predictions = model.predict(image_batch_test, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_roc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_roc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_prc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_prc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, fine_tunning, history_fine)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyGYNkwOyaAf"
   },
   "source": [
    "## Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "in0ZNDUGyjnq",
    "outputId": "083218b8-59a6-48f8-8db9-7531a4754727"
   },
   "outputs": [],
   "source": [
    "base_model.trainable=True\n",
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(len(model.trainable_variables))\n",
    "print('start training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMpKcXi9yjnt"
   },
   "source": [
    "## Fine-Tunning capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def fine_tunning(modelo, base_dir, total_epoch, cp_callback, IMG_SIZE):\n",
    "    train_dataset, test_dataset, validation_dataset, class_names = load_data(base_dir, IMG_SIZE)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Training the model\n",
    "    history_fine = modelo.fit(train_dataset,\n",
    "                              epochs=total_epoch,\n",
    "                              validation_data=validation_dataset,\n",
    "                              callbacks=[cp_callback],\n",
    "                              initial_epoch=15)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time) // 3600))\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "\n",
    "    return history_fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA4yLYHByjnu",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [],
   "source": [
    "total_epoch=30\n",
    "history_fine = fine_tunning(model, base_dir, total_epoch, cp_callback, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('efs/Checkpoints Xception/Modelo entrenado con OCT/Xception_OCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.epoch[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXrv_iYryjnv",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Visualizar metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, validation_dataset, class_names = load_data(base_dir, IMG_SIZE)\n",
    "\n",
    "image_batch_train, train_labels = next(iter(train_dataset))\n",
    "image_batch_test, test_labels = next(iter(test_dataset))\n",
    "\n",
    "train_predictions = model.predict(image_batch_train, batch_size=BATCH_SIZE)\n",
    "test_predictions = model.predict(image_batch_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "baseline_results = model.evaluate(test_dataset,\n",
    "                                  batch_size=32, verbose=0)\n",
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n",
    "\n",
    "plot_roc(\"Train\", train_labels, train_predictions, color='red')\n",
    "plot_roc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plot_prc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_prc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plot_metrics(history, fine_tunning, history_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vdAcIMPyjnw"
   },
   "outputs": [],
   "source": [
    "from utils import visualize\n",
    "\n",
    "visualize(history, baseline_results, modelo, train_labels, test_labels, test_predictions, train_predictions,\n",
    "              fine_tunning=False, history_fine=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBuYJLBdxH1h",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEMYI9dCxiof"
   },
   "source": [
    "## Crear el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus, 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srM-nfFt0e0e"
   },
   "outputs": [],
   "source": [
    "from Modelos_TL.make_model import modelo\n",
    "from Modelos_TL.load_data import load_data\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ENTRENAMIENTO CON OCT PARA METODOLOGIAS 2 Y 4\n",
    "\n",
    "base_dir='efs2/OCT2017' \n",
    "IMG_SIZE = (224, 224)\n",
    "with strategy.scope():\n",
    "    metrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc'),\n",
    "               tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "               ]\n",
    "train_dataset, test_dataset, validation_dataset, class_names= load_data(base_dir, IMG_SIZE, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjrZ30426Fl4",
    "outputId": "c01c9006-c07f-4666-87eb-7af3d4775f39"
   },
   "outputs": [],
   "source": [
    "model_MN, base_model_MN = modelo(IMG_SIZE, 'MobileNetV2', metrics, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MN.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMWGK1fxoDe"
   },
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaKYA_Ay1LuC"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"efs/Checkpoints Mobilenet/Entrenamiento con OCT2017/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XJsMJw5xtg4"
   },
   "source": [
    "## Congelo el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "FLI_CSs8-c6x",
    "outputId": "b5054cce-4220-4edb-eae9-0981e36d8d68"
   },
   "outputs": [],
   "source": [
    "from Modelos_TL.Train_model import train, fine_tunning\n",
    "base_model_MN.trainable=False\n",
    "print(len(model_MN.trainable_variables))\n",
    "with strategy.scope():\n",
    "    model_MN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=metrics)\n",
    "model_MN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7S9dykbx_i3"
   },
   "source": [
    "## Entrenamiento capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuG3QzoW1MZz",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [],
   "source": [
    "history_MN = train(model_MN, base_dir, epoch=3, cp_callback=cp_callback, IMG_SIZE=IMG_SIZE, strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history_MN.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'history.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXBZrG9SyalA",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Visualizar metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj7TlozhyEtI"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "fine_tunning=False\n",
    "history_fine=None\n",
    "baseline_results = model_MN.evaluate(test_dataset,\n",
    "                                  batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "\n",
    "\n",
    "image_batch_train, train_labels = next(iter(train_dataset))\n",
    "image_batch_test, test_labels = next(iter(test_dataset))\n",
    "\n",
    "train_predictions = model_MN.predict(image_batch_train, batch_size=BATCH_SIZE)\n",
    "test_predictions = model_MN.predict(image_batch_test, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Matriz de Confusión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, value in zip(model_MN.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_roc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_roc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_prc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_prc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history_MN, fine_tunning, history_fine)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyGYNkwOyaAf"
   },
   "source": [
    "## Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model_MN.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "in0ZNDUGyjnq",
    "outputId": "083218b8-59a6-48f8-8db9-7531a4754727"
   },
   "outputs": [],
   "source": [
    "base_model_MN.trainable=True\n",
    "len(model_MN.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MN.trainable = True\n",
    "base_model_MN.trainable = True\n",
    "for layer in base_model_MN.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(len(model_MN.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modelos_TL.Train_model import train, fine_tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_MN.epoch[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMpKcXi9yjnt"
   },
   "source": [
    "## Fine-Tunning capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA4yLYHByjnu",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "def fine_tunning(modelo, base_dir, total_epoch, history, cp_callback, IMG_SIZE, strategy):\n",
    "    train_dataset, test_dataset, validation_dataset, class_names = load_data(base_dir, IMG_SIZE, strategy)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Training the model\n",
    "    history_fine = modelo.fit(train_dataset,\n",
    "                              epochs=total_epoch,\n",
    "                              validation_data=validation_dataset,\n",
    "                              callbacks=[cp_callback],\n",
    "                              initial_epoch=history.epoch[-1])\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time) // 3600))\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "\n",
    "    return history_fine\n",
    "\n",
    "\n",
    "total_epoch=16\n",
    "history_fine = fine_tunning(model_MN, base_dir, total_epoch, history_MN, cp_callback, IMG_SIZE, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MN.save('efs2/Checkpoints Mobilenet/Modelo entrenado con OCT/Mobilenet_OCT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine.epoch[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXrv_iYryjnv",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Visualizar metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_batch_train, train_labels = next(iter(train_dataset))\n",
    "image_batch_test, test_labels = next(iter(test_dataset))\n",
    "\n",
    "train_predictions = model_MN.predict(image_batch_train, batch_size=BATCH_SIZE)\n",
    "test_predictions = model_MN.predict(image_batch_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "baseline_results = model_MN.evaluate(test_dataset,\n",
    "                                  batch_size=32, verbose=0)\n",
    "\n",
    "for name, value in zip(model_MN.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n",
    "\n",
    "plot_roc(\"Train\", train_labels, train_predictions, color='red')\n",
    "plot_roc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plot_prc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_prc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plot_metrics(history_MN, fine_tunning, history_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MN.save('efs/Checkpoints Mobilenet/Entrenamiento con OCT2017/MobileNet_OCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vdAcIMPyjnw"
   },
   "outputs": [],
   "source": [
    "from utils import visualize\n",
    "\n",
    "visualize(history, baseline_results, modelo, train_labels, test_labels, test_predictions, train_predictions,\n",
    "              fine_tunning=False, history_fine=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBuYJLBdxH1h",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus, 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEMYI9dCxiof"
   },
   "source": [
    "## Crear el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "srM-nfFt0e0e"
   },
   "outputs": [],
   "source": [
    "from Modelos_TL.make_model import modelo\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ENTRENAMIENTO CON OCT PARA METODOLOGIAS 2 Y 4\n",
    "base_dir='efs2/OCT2017' \n",
    "IMG_SIZE = (150, 150)\n",
    "with strategy.scope():\n",
    "    metrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc'),\n",
    "               tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjrZ30426Fl4",
    "outputId": "c01c9006-c07f-4666-87eb-7af3d4775f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_1  [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_1 (Tenso [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 5, 5, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 24,637,313\n",
      "Trainable params: 24,584,193\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model, base_model = modelo(IMG_SIZE, 'ResNet50', metrics, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMWGK1fxoDe"
   },
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IaKYA_Ay1LuC"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XJsMJw5xtg4"
   },
   "source": [
    "## Congelo el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "FLI_CSs8-c6x",
    "outputId": "b5054cce-4220-4edb-eae9-0981e36d8d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from Modelos_TL.Train_model import train, fine_tunning\n",
    "base_model.trainable=False\n",
    "print(len(model.trainable_variables))\n",
    "with strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7S9dykbx_i3"
   },
   "source": [
    "## Entrenamiento capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuG3QzoW1MZz",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72136 files belonging to 2 classes.\n",
      "Found 726 files belonging to 2 classes.\n",
      "start training\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 4 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 4 all-reduces with algorithm = nccl, num_packs = 1\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.2443 - tp: 20593.0000 - fp: 3508.0000 - tn: 37713.0000 - fn: 3154.0000 - accuracy: 0.8975 - precision: 0.8544 - recall: 0.8672 - auc: 0.9604 - prc: 0.9215\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98072, saving model to efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\n",
      "508/508 [==============================] - 311s 613ms/step - loss: 0.2443 - tp: 20593.0000 - fp: 3508.0000 - tn: 37713.0000 - fn: 3154.0000 - accuracy: 0.8975 - precision: 0.8544 - recall: 0.8672 - auc: 0.9604 - prc: 0.9215 - val_loss: 0.0927 - val_tp: 238.0000 - val_fp: 10.0000 - val_tn: 474.0000 - val_fn: 4.0000 - val_accuracy: 0.9807 - val_precision: 0.9597 - val_recall: 0.9835 - val_auc: 0.9958 - val_prc: 0.9901\n",
      "Epoch 2/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1966 - tp: 21565.0000 - fp: 2918.0000 - tn: 38306.0000 - fn: 2179.0000 - accuracy: 0.9215 - precision: 0.8808 - recall: 0.9082 - auc: 0.9734 - prc: 0.9445\n",
      "Epoch 00002: val_accuracy did not improve from 0.98072\n",
      "508/508 [==============================] - 290s 571ms/step - loss: 0.1966 - tp: 21565.0000 - fp: 2918.0000 - tn: 38306.0000 - fn: 2179.0000 - accuracy: 0.9215 - precision: 0.8808 - recall: 0.9082 - auc: 0.9734 - prc: 0.9445 - val_loss: 0.0869 - val_tp: 239.0000 - val_fp: 13.0000 - val_tn: 471.0000 - val_fn: 3.0000 - val_accuracy: 0.9780 - val_precision: 0.9484 - val_recall: 0.9876 - val_auc: 0.9967 - val_prc: 0.9926\n",
      "Epoch 3/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1840 - tp: 21765.0000 - fp: 2749.0000 - tn: 38485.0000 - fn: 1969.0000 - accuracy: 0.9274 - precision: 0.8879 - recall: 0.9170 - auc: 0.9766 - prc: 0.9506\n",
      "Epoch 00003: val_accuracy improved from 0.98072 to 0.98209, saving model to efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\n",
      "508/508 [==============================] - 288s 566ms/step - loss: 0.1840 - tp: 21765.0000 - fp: 2749.0000 - tn: 38485.0000 - fn: 1969.0000 - accuracy: 0.9274 - precision: 0.8879 - recall: 0.9170 - auc: 0.9766 - prc: 0.9506 - val_loss: 0.0714 - val_tp: 239.0000 - val_fp: 10.0000 - val_tn: 474.0000 - val_fn: 3.0000 - val_accuracy: 0.9821 - val_precision: 0.9598 - val_recall: 0.9876 - val_auc: 0.9980 - val_prc: 0.9960\n",
      "Epoch 4/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1811 - tp: 21840.0000 - fp: 2746.0000 - tn: 38468.0000 - fn: 1914.0000 - accuracy: 0.9283 - precision: 0.8883 - recall: 0.9194 - auc: 0.9770 - prc: 0.9507\n",
      "Epoch 00004: val_accuracy did not improve from 0.98209\n",
      "508/508 [==============================] - 289s 569ms/step - loss: 0.1811 - tp: 21840.0000 - fp: 2746.0000 - tn: 38468.0000 - fn: 1914.0000 - accuracy: 0.9283 - precision: 0.8883 - recall: 0.9194 - auc: 0.9770 - prc: 0.9507 - val_loss: 0.0709 - val_tp: 238.0000 - val_fp: 9.0000 - val_tn: 475.0000 - val_fn: 4.0000 - val_accuracy: 0.9821 - val_precision: 0.9636 - val_recall: 0.9835 - val_auc: 0.9973 - val_prc: 0.9937\n",
      "Epoch 5/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1740 - tp: 21886.0000 - fp: 2631.0000 - tn: 38606.0000 - fn: 1845.0000 - accuracy: 0.9311 - precision: 0.8927 - recall: 0.9223 - auc: 0.9789 - prc: 0.9554\n",
      "Epoch 00005: val_accuracy did not improve from 0.98209\n",
      "508/508 [==============================] - 293s 578ms/step - loss: 0.1740 - tp: 21886.0000 - fp: 2631.0000 - tn: 38606.0000 - fn: 1845.0000 - accuracy: 0.9311 - precision: 0.8927 - recall: 0.9223 - auc: 0.9789 - prc: 0.9554 - val_loss: 0.0676 - val_tp: 235.0000 - val_fp: 9.0000 - val_tn: 475.0000 - val_fn: 7.0000 - val_accuracy: 0.9780 - val_precision: 0.9631 - val_recall: 0.9711 - val_auc: 0.9975 - val_prc: 0.9945\n",
      "Epoch 6/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1695 - tp: 21995.0000 - fp: 2574.0000 - tn: 38659.0000 - fn: 1740.0000 - accuracy: 0.9336 - precision: 0.8952 - recall: 0.9267 - auc: 0.9797 - prc: 0.9571\n",
      "Epoch 00006: val_accuracy improved from 0.98209 to 0.98485, saving model to efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\n",
      "508/508 [==============================] - 291s 573ms/step - loss: 0.1695 - tp: 21995.0000 - fp: 2574.0000 - tn: 38659.0000 - fn: 1740.0000 - accuracy: 0.9336 - precision: 0.8952 - recall: 0.9267 - auc: 0.9797 - prc: 0.9571 - val_loss: 0.0671 - val_tp: 236.0000 - val_fp: 5.0000 - val_tn: 479.0000 - val_fn: 6.0000 - val_accuracy: 0.9848 - val_precision: 0.9793 - val_recall: 0.9752 - val_auc: 0.9973 - val_prc: 0.9933\n",
      "Epoch 7/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1674 - tp: 22043.0000 - fp: 2542.0000 - tn: 38674.0000 - fn: 1709.0000 - accuracy: 0.9346 - precision: 0.8966 - recall: 0.9280 - auc: 0.9801 - prc: 0.9575\n",
      "Epoch 00007: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 289s 570ms/step - loss: 0.1674 - tp: 22043.0000 - fp: 2542.0000 - tn: 38674.0000 - fn: 1709.0000 - accuracy: 0.9346 - precision: 0.8966 - recall: 0.9280 - auc: 0.9801 - prc: 0.9575 - val_loss: 0.0774 - val_tp: 239.0000 - val_fp: 15.0000 - val_tn: 469.0000 - val_fn: 3.0000 - val_accuracy: 0.9752 - val_precision: 0.9409 - val_recall: 0.9876 - val_auc: 0.9972 - val_prc: 0.9935\n",
      "Epoch 8/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1654 - tp: 22077.0000 - fp: 2498.0000 - tn: 38730.0000 - fn: 1663.0000 - accuracy: 0.9360 - precision: 0.8984 - recall: 0.9299 - auc: 0.9806 - prc: 0.9581\n",
      "Epoch 00008: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 290s 571ms/step - loss: 0.1654 - tp: 22077.0000 - fp: 2498.0000 - tn: 38730.0000 - fn: 1663.0000 - accuracy: 0.9360 - precision: 0.8984 - recall: 0.9299 - auc: 0.9806 - prc: 0.9581 - val_loss: 0.0700 - val_tp: 239.0000 - val_fp: 12.0000 - val_tn: 472.0000 - val_fn: 3.0000 - val_accuracy: 0.9793 - val_precision: 0.9522 - val_recall: 0.9876 - val_auc: 0.9974 - val_prc: 0.9938\n",
      "Epoch 9/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1639 - tp: 22058.0000 - fp: 2529.0000 - tn: 38716.0000 - fn: 1665.0000 - accuracy: 0.9354 - precision: 0.8971 - recall: 0.9298 - auc: 0.9809 - prc: 0.9592\n",
      "Epoch 00009: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 293s 577ms/step - loss: 0.1639 - tp: 22058.0000 - fp: 2529.0000 - tn: 38716.0000 - fn: 1665.0000 - accuracy: 0.9354 - precision: 0.8971 - recall: 0.9298 - auc: 0.9809 - prc: 0.9592 - val_loss: 0.0718 - val_tp: 241.0000 - val_fp: 14.0000 - val_tn: 470.0000 - val_fn: 1.0000 - val_accuracy: 0.9793 - val_precision: 0.9451 - val_recall: 0.9959 - val_auc: 0.9976 - val_prc: 0.9942\n",
      "Epoch 10/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1631 - tp: 22091.0000 - fp: 2493.0000 - tn: 38742.0000 - fn: 1642.0000 - accuracy: 0.9364 - precision: 0.8986 - recall: 0.9308 - auc: 0.9811 - prc: 0.9603\n",
      "Epoch 00010: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 289s 569ms/step - loss: 0.1631 - tp: 22091.0000 - fp: 2493.0000 - tn: 38742.0000 - fn: 1642.0000 - accuracy: 0.9364 - precision: 0.8986 - recall: 0.9308 - auc: 0.9811 - prc: 0.9603 - val_loss: 0.0602 - val_tp: 237.0000 - val_fp: 6.0000 - val_tn: 478.0000 - val_fn: 5.0000 - val_accuracy: 0.9848 - val_precision: 0.9753 - val_recall: 0.9793 - val_auc: 0.9980 - val_prc: 0.9958\n",
      "Epoch 11/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1612 - tp: 22123.0000 - fp: 2473.0000 - tn: 38761.0000 - fn: 1611.0000 - accuracy: 0.9371 - precision: 0.8995 - recall: 0.9321 - auc: 0.9815 - prc: 0.9608\n",
      "Epoch 00011: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 291s 572ms/step - loss: 0.1612 - tp: 22123.0000 - fp: 2473.0000 - tn: 38761.0000 - fn: 1611.0000 - accuracy: 0.9371 - precision: 0.8995 - recall: 0.9321 - auc: 0.9815 - prc: 0.9608 - val_loss: 0.0653 - val_tp: 241.0000 - val_fp: 13.0000 - val_tn: 471.0000 - val_fn: 1.0000 - val_accuracy: 0.9807 - val_precision: 0.9488 - val_recall: 0.9959 - val_auc: 0.9984 - val_prc: 0.9966\n",
      "Epoch 12/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1589 - tp: 22117.0000 - fp: 2485.0000 - tn: 38755.0000 - fn: 1611.0000 - accuracy: 0.9370 - precision: 0.8990 - recall: 0.9321 - auc: 0.9821 - prc: 0.9620\n",
      "Epoch 00012: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 289s 569ms/step - loss: 0.1589 - tp: 22117.0000 - fp: 2485.0000 - tn: 38755.0000 - fn: 1611.0000 - accuracy: 0.9370 - precision: 0.8990 - recall: 0.9321 - auc: 0.9821 - prc: 0.9620 - val_loss: 0.0665 - val_tp: 240.0000 - val_fp: 13.0000 - val_tn: 471.0000 - val_fn: 2.0000 - val_accuracy: 0.9793 - val_precision: 0.9486 - val_recall: 0.9917 - val_auc: 0.9982 - val_prc: 0.9961\n",
      "Epoch 13/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1587 - tp: 22162.0000 - fp: 2410.0000 - tn: 38833.0000 - fn: 1563.0000 - accuracy: 0.9388 - precision: 0.9019 - recall: 0.9341 - auc: 0.9819 - prc: 0.9607\n",
      "Epoch 00013: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 290s 571ms/step - loss: 0.1587 - tp: 22162.0000 - fp: 2410.0000 - tn: 38833.0000 - fn: 1563.0000 - accuracy: 0.9388 - precision: 0.9019 - recall: 0.9341 - auc: 0.9819 - prc: 0.9607 - val_loss: 0.0594 - val_tp: 241.0000 - val_fp: 12.0000 - val_tn: 472.0000 - val_fn: 1.0000 - val_accuracy: 0.9821 - val_precision: 0.9526 - val_recall: 0.9959 - val_auc: 0.9985 - val_prc: 0.9969\n",
      "Epoch 14/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1546 - tp: 22160.0000 - fp: 2394.0000 - tn: 38854.0000 - fn: 1560.0000 - accuracy: 0.9391 - precision: 0.9025 - recall: 0.9342 - auc: 0.9829 - prc: 0.9643\n",
      "Epoch 00014: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 287s 565ms/step - loss: 0.1546 - tp: 22160.0000 - fp: 2394.0000 - tn: 38854.0000 - fn: 1560.0000 - accuracy: 0.9391 - precision: 0.9025 - recall: 0.9342 - auc: 0.9829 - prc: 0.9643 - val_loss: 0.0602 - val_tp: 241.0000 - val_fp: 13.0000 - val_tn: 471.0000 - val_fn: 1.0000 - val_accuracy: 0.9807 - val_precision: 0.9488 - val_recall: 0.9959 - val_auc: 0.9983 - val_prc: 0.9963\n",
      "Epoch 15/15\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1552 - tp: 22229.0000 - fp: 2397.0000 - tn: 38825.0000 - fn: 1517.0000 - accuracy: 0.9398 - precision: 0.9027 - recall: 0.9361 - auc: 0.9826 - prc: 0.9626\n",
      "Epoch 00015: val_accuracy did not improve from 0.98485\n",
      "508/508 [==============================] - 289s 569ms/step - loss: 0.1552 - tp: 22229.0000 - fp: 2397.0000 - tn: 38825.0000 - fn: 1517.0000 - accuracy: 0.9398 - precision: 0.9027 - recall: 0.9361 - auc: 0.9826 - prc: 0.9626 - val_loss: 0.0643 - val_tp: 240.0000 - val_fp: 14.0000 - val_tn: 470.0000 - val_fn: 2.0000 - val_accuracy: 0.9780 - val_precision: 0.9449 - val_recall: 0.9917 - val_auc: 0.9982 - val_prc: 0.9961\n",
      "--- Time taken to train : 1.0 hours ---\n"
     ]
    }
   ],
   "source": [
    "epoch=15\n",
    "history = train(model, base_dir, epoch, cp_callback, IMG_SIZE, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "checkpoint_path = \"efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\"\n",
    "with strategy.scope():\n",
    "    model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXBZrG9SyalA",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Visualizar metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj7TlozhyEtI"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "fine_tunning=False\n",
    "history_fine=None\n",
    "BATCH_SIZE=32\n",
    "baseline_results = model.evaluate(test_dataset,\n",
    "                                  batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "\n",
    "\n",
    "image_batch_train, train_labels = next(iter(train_dataset))\n",
    "image_batch_test, test_labels = next(iter(test_dataset))\n",
    "\n",
    "train_predictions = model.predict(image_batch_train, batch_size=BATCH_SIZE)\n",
    "test_predictions = model.predict(image_batch_test, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_roc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_roc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_prc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_prc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, fine_tunning, history_fine)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyGYNkwOyaAf"
   },
   "source": [
    "## Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "in0ZNDUGyjnq",
    "outputId": "083218b8-59a6-48f8-8db9-7531a4754727"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable=True\n",
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "start training\n"
     ]
    }
   ],
   "source": [
    "model.trainable = True\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(len(model.trainable_variables))\n",
    "print('start training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "\n",
    "def fine_tunningg(modelo, base_dir, total_epoch, history, cp_callback, IMG_SIZE, strategy):\n",
    "    train_dataset, test_dataset, validation_dataset, class_names = load_data(base_dir, IMG_SIZE, strategy)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Training the model\n",
    "    history_fine = modelo.fit(train_dataset,\n",
    "                              epochs=total_epoch,\n",
    "                              validation_data=validation_dataset,\n",
    "                              callbacks=[cp_callback],\n",
    "                              initial_epoch=history)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time) // 3600))\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "\n",
    "    return history_fine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMpKcXi9yjnt"
   },
   "source": [
    "## Fine-Tunning capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA4yLYHByjnu",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72136 files belonging to 2 classes.\n",
      "Found 726 files belonging to 2 classes.\n",
      "Epoch 16/30\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 106 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 106 all-reduces with algorithm = nccl, num_packs = 1\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1178 - tp: 22812.0000 - fp: 1814.0000 - tn: 39428.0000 - fn: 914.0000 - accuracy: 0.9580 - precision: 0.9263 - recall: 0.9615 - auc: 0.9888 - prc: 0.9750\n",
      "Epoch 00016: val_accuracy improved from -inf to 0.99036, saving model to efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\n",
      "508/508 [==============================] - 516s 1s/step - loss: 0.1178 - tp: 22812.0000 - fp: 1814.0000 - tn: 39428.0000 - fn: 914.0000 - accuracy: 0.9580 - precision: 0.9263 - recall: 0.9615 - auc: 0.9888 - prc: 0.9750 - val_loss: 0.0266 - val_tp: 239.0000 - val_fp: 4.0000 - val_tn: 480.0000 - val_fn: 3.0000 - val_accuracy: 0.9904 - val_precision: 0.9835 - val_recall: 0.9876 - val_auc: 0.9996 - val_prc: 0.9991\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0856 - tp: 23188.0000 - fp: 1342.0000 - tn: 39905.0000 - fn: 533.0000 - accuracy: 0.9711 - precision: 0.9453 - recall: 0.9775 - auc: 0.9929 - prc: 0.9834\n",
      "Epoch 00017: val_accuracy improved from 0.99036 to 0.99174, saving model to efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\n",
      "508/508 [==============================] - 261s 513ms/step - loss: 0.0856 - tp: 23188.0000 - fp: 1342.0000 - tn: 39905.0000 - fn: 533.0000 - accuracy: 0.9711 - precision: 0.9453 - recall: 0.9775 - auc: 0.9929 - prc: 0.9834 - val_loss: 0.0236 - val_tp: 241.0000 - val_fp: 5.0000 - val_tn: 479.0000 - val_fn: 1.0000 - val_accuracy: 0.9917 - val_precision: 0.9797 - val_recall: 0.9959 - val_auc: 0.9997 - val_prc: 0.9994\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0773 - tp: 23233.0000 - fp: 1194.0000 - tn: 40059.0000 - fn: 482.0000 - accuracy: 0.9742 - precision: 0.9511 - recall: 0.9797 - auc: 0.9940 - prc: 0.9860\n",
      "Epoch 00018: val_accuracy improved from 0.99174 to 0.99311, saving model to efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\n",
      "508/508 [==============================] - 265s 521ms/step - loss: 0.0773 - tp: 23233.0000 - fp: 1194.0000 - tn: 40059.0000 - fn: 482.0000 - accuracy: 0.9742 - precision: 0.9511 - recall: 0.9797 - auc: 0.9940 - prc: 0.9860 - val_loss: 0.0206 - val_tp: 241.0000 - val_fp: 4.0000 - val_tn: 480.0000 - val_fn: 1.0000 - val_accuracy: 0.9931 - val_precision: 0.9837 - val_recall: 0.9959 - val_auc: 0.9997 - val_prc: 0.9994\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0725 - tp: 23261.0000 - fp: 1109.0000 - tn: 40148.0000 - fn: 450.0000 - accuracy: 0.9760 - precision: 0.9545 - recall: 0.9810 - auc: 0.9946 - prc: 0.9870\n",
      "Epoch 00019: val_accuracy did not improve from 0.99311\n",
      "508/508 [==============================] - 259s 511ms/step - loss: 0.0725 - tp: 23261.0000 - fp: 1109.0000 - tn: 40148.0000 - fn: 450.0000 - accuracy: 0.9760 - precision: 0.9545 - recall: 0.9810 - auc: 0.9946 - prc: 0.9870 - val_loss: 0.0207 - val_tp: 240.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 2.0000 - val_accuracy: 0.9931 - val_precision: 0.9877 - val_recall: 0.9917 - val_auc: 0.9998 - val_prc: 0.9995\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0671 - tp: 23283.0000 - fp: 1036.0000 - tn: 40218.0000 - fn: 431.0000 - accuracy: 0.9774 - precision: 0.9574 - recall: 0.9818 - auc: 0.9955 - prc: 0.9892\n",
      "Epoch 00020: val_accuracy did not improve from 0.99311\n",
      "508/508 [==============================] - 257s 505ms/step - loss: 0.0671 - tp: 23283.0000 - fp: 1036.0000 - tn: 40218.0000 - fn: 431.0000 - accuracy: 0.9774 - precision: 0.9574 - recall: 0.9818 - auc: 0.9955 - prc: 0.9892 - val_loss: 0.0236 - val_tp: 240.0000 - val_fp: 4.0000 - val_tn: 480.0000 - val_fn: 2.0000 - val_accuracy: 0.9917 - val_precision: 0.9836 - val_recall: 0.9917 - val_auc: 0.9996 - val_prc: 0.9993\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0651 - tp: 23336.0000 - fp: 1003.0000 - tn: 40234.0000 - fn: 395.0000 - accuracy: 0.9785 - precision: 0.9588 - recall: 0.9834 - auc: 0.9954 - prc: 0.9884\n",
      "Epoch 00021: val_accuracy did not improve from 0.99311\n",
      "508/508 [==============================] - 258s 508ms/step - loss: 0.0651 - tp: 23336.0000 - fp: 1003.0000 - tn: 40234.0000 - fn: 395.0000 - accuracy: 0.9785 - precision: 0.9588 - recall: 0.9834 - auc: 0.9954 - prc: 0.9884 - val_loss: 0.0189 - val_tp: 240.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 2.0000 - val_accuracy: 0.9931 - val_precision: 0.9877 - val_recall: 0.9917 - val_auc: 0.9999 - val_prc: 0.9997\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0637 - tp: 23318.0000 - fp: 983.0000 - tn: 40268.0000 - fn: 399.0000 - accuracy: 0.9787 - precision: 0.9595 - recall: 0.9832 - auc: 0.9958 - prc: 0.9900\n",
      "Epoch 00022: val_accuracy improved from 0.99311 to 0.99449, saving model to efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\n",
      "508/508 [==============================] - 262s 516ms/step - loss: 0.0637 - tp: 23318.0000 - fp: 983.0000 - tn: 40268.0000 - fn: 399.0000 - accuracy: 0.9787 - precision: 0.9595 - recall: 0.9832 - auc: 0.9958 - prc: 0.9900 - val_loss: 0.0169 - val_tp: 241.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 1.0000 - val_accuracy: 0.9945 - val_precision: 0.9877 - val_recall: 0.9959 - val_auc: 0.9999 - val_prc: 0.9998\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0613 - tp: 23353.0000 - fp: 951.0000 - tn: 40284.0000 - fn: 380.0000 - accuracy: 0.9795 - precision: 0.9609 - recall: 0.9840 - auc: 0.9961 - prc: 0.9909\n",
      "Epoch 00023: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 259s 510ms/step - loss: 0.0613 - tp: 23353.0000 - fp: 951.0000 - tn: 40284.0000 - fn: 380.0000 - accuracy: 0.9795 - precision: 0.9609 - recall: 0.9840 - auc: 0.9961 - prc: 0.9909 - val_loss: 0.0234 - val_tp: 240.0000 - val_fp: 4.0000 - val_tn: 480.0000 - val_fn: 2.0000 - val_accuracy: 0.9917 - val_precision: 0.9836 - val_recall: 0.9917 - val_auc: 0.9998 - val_prc: 0.9996\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0572 - tp: 23365.0000 - fp: 873.0000 - tn: 40375.0000 - fn: 355.0000 - accuracy: 0.9811 - precision: 0.9640 - recall: 0.9850 - auc: 0.9965 - prc: 0.9916\n",
      "Epoch 00024: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 261s 514ms/step - loss: 0.0572 - tp: 23365.0000 - fp: 873.0000 - tn: 40375.0000 - fn: 355.0000 - accuracy: 0.9811 - precision: 0.9640 - recall: 0.9850 - auc: 0.9965 - prc: 0.9916 - val_loss: 0.0196 - val_tp: 240.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 2.0000 - val_accuracy: 0.9931 - val_precision: 0.9877 - val_recall: 0.9917 - val_auc: 0.9998 - val_prc: 0.9997\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0563 - tp: 23342.0000 - fp: 876.0000 - tn: 40388.0000 - fn: 362.0000 - accuracy: 0.9809 - precision: 0.9638 - recall: 0.9847 - auc: 0.9966 - prc: 0.9923\n",
      "Epoch 00025: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 261s 514ms/step - loss: 0.0563 - tp: 23342.0000 - fp: 876.0000 - tn: 40388.0000 - fn: 362.0000 - accuracy: 0.9809 - precision: 0.9638 - recall: 0.9847 - auc: 0.9966 - prc: 0.9923 - val_loss: 0.0164 - val_tp: 241.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 1.0000 - val_accuracy: 0.9945 - val_precision: 0.9877 - val_recall: 0.9959 - val_auc: 0.9999 - val_prc: 0.9998\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0549 - tp: 23360.0000 - fp: 852.0000 - tn: 40396.0000 - fn: 360.0000 - accuracy: 0.9813 - precision: 0.9648 - recall: 0.9848 - auc: 0.9968 - prc: 0.9920\n",
      "Epoch 00026: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 260s 511ms/step - loss: 0.0549 - tp: 23360.0000 - fp: 852.0000 - tn: 40396.0000 - fn: 360.0000 - accuracy: 0.9813 - precision: 0.9648 - recall: 0.9848 - auc: 0.9968 - prc: 0.9920 - val_loss: 0.0159 - val_tp: 241.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 1.0000 - val_accuracy: 0.9945 - val_precision: 0.9877 - val_recall: 0.9959 - val_auc: 0.9999 - val_prc: 0.9998\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0521 - tp: 23390.0000 - fp: 796.0000 - tn: 40447.0000 - fn: 335.0000 - accuracy: 0.9826 - precision: 0.9671 - recall: 0.9859 - auc: 0.9970 - prc: 0.9930\n",
      "Epoch 00027: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 261s 513ms/step - loss: 0.0521 - tp: 23390.0000 - fp: 796.0000 - tn: 40447.0000 - fn: 335.0000 - accuracy: 0.9826 - precision: 0.9671 - recall: 0.9859 - auc: 0.9970 - prc: 0.9930 - val_loss: 0.0146 - val_tp: 240.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 2.0000 - val_accuracy: 0.9931 - val_precision: 0.9877 - val_recall: 0.9917 - val_auc: 0.9999 - val_prc: 0.9998\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0522 - tp: 23400.0000 - fp: 793.0000 - tn: 40457.0000 - fn: 318.0000 - accuracy: 0.9829 - precision: 0.9672 - recall: 0.9866 - auc: 0.9971 - prc: 0.9933\n",
      "Epoch 00028: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 256s 505ms/step - loss: 0.0522 - tp: 23400.0000 - fp: 793.0000 - tn: 40457.0000 - fn: 318.0000 - accuracy: 0.9829 - precision: 0.9672 - recall: 0.9866 - auc: 0.9971 - prc: 0.9933 - val_loss: 0.0176 - val_tp: 240.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 2.0000 - val_accuracy: 0.9931 - val_precision: 0.9877 - val_recall: 0.9917 - val_auc: 0.9999 - val_prc: 0.9997\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0514 - tp: 23365.0000 - fp: 799.0000 - tn: 40467.0000 - fn: 337.0000 - accuracy: 0.9825 - precision: 0.9669 - recall: 0.9858 - auc: 0.9972 - prc: 0.9935\n",
      "Epoch 00029: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 256s 504ms/step - loss: 0.0514 - tp: 23365.0000 - fp: 799.0000 - tn: 40467.0000 - fn: 337.0000 - accuracy: 0.9825 - precision: 0.9669 - recall: 0.9858 - auc: 0.9972 - prc: 0.9935 - val_loss: 0.0175 - val_tp: 240.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 2.0000 - val_accuracy: 0.9931 - val_precision: 0.9877 - val_recall: 0.9917 - val_auc: 0.9999 - val_prc: 0.9998\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0488 - tp: 23411.0000 - fp: 765.0000 - tn: 40474.0000 - fn: 318.0000 - accuracy: 0.9833 - precision: 0.9684 - recall: 0.9866 - auc: 0.9975 - prc: 0.9942\n",
      "Epoch 00030: val_accuracy did not improve from 0.99449\n",
      "508/508 [==============================] - 256s 505ms/step - loss: 0.0488 - tp: 23411.0000 - fp: 765.0000 - tn: 40474.0000 - fn: 318.0000 - accuracy: 0.9833 - precision: 0.9684 - recall: 0.9866 - auc: 0.9975 - prc: 0.9942 - val_loss: 0.0195 - val_tp: 240.0000 - val_fp: 3.0000 - val_tn: 481.0000 - val_fn: 2.0000 - val_accuracy: 0.9931 - val_precision: 0.9877 - val_recall: 0.9917 - val_auc: 0.9999 - val_prc: 0.9997\n",
      "--- Time taken to train : 1.0 hours ---\n"
     ]
    }
   ],
   "source": [
    "total_epoch=30\n",
    "from Modelos_TL.Train_model import train, fine_tunning\n",
    "history_fine = fine_tunningg(model, base_dir, total_epoch, 15, cp_callback, IMG_SIZE, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.save('efs2/Checkpoints ResNet50/modelo entrenado con OCT/ResNet50_OCT.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXrv_iYryjnv"
   },
   "source": [
    "### Visualizar metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, validation_dataset, class_names = load_data(base_dir, IMG_SIZE)\n",
    "\n",
    "image_batch_train, train_labels = next(iter(train_dataset))\n",
    "image_batch_test, test_labels = next(iter(test_dataset))\n",
    "\n",
    "train_predictions = model.predict(image_batch_train, batch_size=BATCH_SIZE)\n",
    "test_predictions = model.predict(image_batch_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "baseline_results = model.evaluate(test_dataset,\n",
    "                                  batch_size=32, verbose=0)\n",
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n",
    "\n",
    "plot_roc(\"Train\", train_labels, train_predictions, color='red')\n",
    "plot_roc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plot_prc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_prc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plot_metrics(history, fine_tunning, history_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vdAcIMPyjnw"
   },
   "outputs": [],
   "source": [
    "from utils import visualize\n",
    "\n",
    "visualize(history, baseline_results, modelo, train_labels, test_labels, test_predictions, train_predictions,\n",
    "              fine_tunning=False, history_fine=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBuYJLBdxH1h"
   },
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus, 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEMYI9dCxiof"
   },
   "source": [
    "## Crear el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "srM-nfFt0e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_RealDiv (TensorF [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowO [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Functional)    (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 22,852,385\n",
      "Trainable params: 22,817,953\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from Modelos_TL.make_model import modelo\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ENTRENAMIENTO CON OCT PARA METODOLOGIAS 2 Y 4\n",
    "base_dir='efs2/OCT2017' \n",
    "IMG_SIZE = (150, 150)\n",
    "with strategy.scope():\n",
    "    metrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc'),\n",
    "               tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "               ]\n",
    "    model, base_model = modelo(IMG_SIZE, 'Inception', metrics, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMWGK1fxoDe"
   },
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir 'efs2/Checkpoints Inception'\n",
    "!mkdir 'efs2/Checkpoints Inception/Entrenamiento con OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IaKYA_Ay1LuC"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"efs2/Checkpoints Inception/Entrenamiento con OCT/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XJsMJw5xtg4"
   },
   "source": [
    "## Congelo el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "FLI_CSs8-c6x",
    "outputId": "b5054cce-4220-4edb-eae9-0981e36d8d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from Modelos_TL.Train_model import train, fine_tunning\n",
    "base_model.trainable=False\n",
    "print(len(model.trainable_variables))\n",
    "with strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7S9dykbx_i3"
   },
   "source": [
    "## Entrenamiento capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuG3QzoW1MZz",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [],
   "source": [
    "epoch=15\n",
    "history = train(model, base_dir, epoch, cp_callback, IMG_SIZE, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "checkpoint_path = \"efs2/Checkpoints ResNet50/Entrenamiento con OCT/cp.ckpt\"\n",
    "with strategy.scope():\n",
    "    model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXBZrG9SyalA",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Visualizar metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj7TlozhyEtI"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "fine_tunning=False\n",
    "history_fine=None\n",
    "BATCH_SIZE=32\n",
    "baseline_results = model.evaluate(test_dataset,\n",
    "                                  batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "\n",
    "\n",
    "image_batch_train, train_labels = next(iter(train_dataset))\n",
    "image_batch_test, test_labels = next(iter(test_dataset))\n",
    "\n",
    "train_predictions = model.predict(image_batch_train, batch_size=BATCH_SIZE)\n",
    "test_predictions = model.predict(image_batch_test, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_roc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_roc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_prc(\"Train\", train_labels, train_predictions, color=colors[0])\n",
    "plot_prc(\"Test\", test_labels, test_predictions, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, fine_tunning, history_fine)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyGYNkwOyaAf"
   },
   "source": [
    "## Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "in0ZNDUGyjnq",
    "outputId": "083218b8-59a6-48f8-8db9-7531a4754727"
   },
   "outputs": [],
   "source": [
    "base_model.trainable=True\n",
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(len(model.trainable_variables))\n",
    "print('start training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from Modelos_TL.load_data import load_data\n",
    "\n",
    "\n",
    "\n",
    "def fine_tunningg(modelo, base_dir, total_epoch, history, cp_callback, IMG_SIZE, strategy):\n",
    "    train_dataset, test_dataset, validation_dataset, class_names = load_data(base_dir, IMG_SIZE, strategy)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Training the model\n",
    "    history_fine = modelo.fit(train_dataset,\n",
    "                              epochs=total_epoch,\n",
    "                              validation_data=validation_dataset,\n",
    "                              callbacks=[cp_callback],\n",
    "                              initial_epoch=history)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time) // 3600))\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "\n",
    "    return history_fine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMpKcXi9yjnt"
   },
   "source": [
    "## Fine-Tunning capas superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA4yLYHByjnu",
    "outputId": "bb7ea72c-cf74-4f34-b3b9-dac1e3876807"
   },
   "outputs": [],
   "source": [
    "total_epoch=30\n",
    "from Modelos_TL.Train_model import train, fine_tunning\n",
    "history_fine = fine_tunningg(model, base_dir, total_epoch, 15, cp_callback, IMG_SIZE, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.save('efs2/Checkpoints ResNet50/modelo entrenado con OCT/ResNet50_OCT.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# OpticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus, 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from OpticNet.OpticNet71 import OpticNet\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Multiply, GlobalAveragePooling2D, Add, Dense, Activation, Maximum, ZeroPadding2D, \\\n",
    "    BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Lambda, UpSampling2D, \\\n",
    "    DepthwiseConv2D, SeparableConv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "input_size= 160\n",
    "num_of_classes= 2\n",
    "with strategy.scope():\n",
    "    model = OpticNet(input_size, num_of_classes,strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OpticNet.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='efs2/OCT2017' \n",
    "train_batches, test_batches, val_batches, classes= load_data(base_dir, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_path = \"efs2/Checkpoints OpticNet/OpticNet_OCT_binary2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.load_weights(\"efs2/Checkpoints OpticNet/OpticNet_OCT_binary/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OpticNet.load_data import load_data\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    model.trainable=True\n",
    "    model.compile(Adam(lr=.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OpticNet.Train_Model import train\n",
    "epoch= 2\n",
    "history = train(model, base_dir, epoch, cb, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 16\n",
    "batch_size = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                           width_shift_range=0.2,\n",
    "                           height_shift_range=0.2,\n",
    "                           shear_range=0.2,\n",
    "                           zoom_range=0.2,\n",
    "                           rescale=1.0 / 255,\n",
    "                           horizontal_flip=True,\n",
    "                           fill_mode='nearest', \n",
    "                           validation_split=0.05)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "classes = ['NORMAL', 'AR']\n",
    "train_batches = train_datagen.flow_from_directory(train_dir,\n",
    "                                          target_size=(160, 160),\n",
    "                                          classes=classes,\n",
    "                                          subset='training',\n",
    "                                          shuffle=True,\n",
    "                                          batch_size=batch_size,\n",
    "                                          class_mode='binary',\n",
    "                                          color_mode='rgb')\n",
    "test_batches = test_datagen.flow_from_directory(test_dir,\n",
    "                                        target_size=(160, 160),\n",
    "                                        classes=classes,\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode='binary',\n",
    "                                        color_mode='rgb')\n",
    "val_batches = train_datagen.flow_from_directory(train_dir,\n",
    "                                       subset='validation',\n",
    "                                       target_size=(160, 160),\n",
    "                                       classes=classes,\n",
    "                                       shuffle=True,\n",
    "                                       batch_size=batch_size,\n",
    "                                       class_mode='binary',\n",
    "                                       color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Multiply, GlobalAveragePooling2D, Add, Dense, Activation, Maximum, ZeroPadding2D, \\\n",
    "    BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Lambda, UpSampling2D, \\\n",
    "    DepthwiseConv2D, SeparableConv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "\n",
    "def res_conv(X, filters, base, s):\n",
    "    name_base = base + '/branch'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    ##### Branch1 is the main path and Branch2 is the shortcut path #####\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### Branch1 #####\n",
    "    # First component of Branch1\n",
    "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_1')(X)\n",
    "    X = Activation('relu', name=name_base + '1/relu_1')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=name_base + '1/conv_1',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Second component of Branch1\n",
    "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_2')(X)\n",
    "    X = Activation('relu', name=name_base + '1/relu_2')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(2, 2), strides=(s, s), padding='same', name=name_base + '1/conv_2',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Third component of Branch1\n",
    "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_3')(X)\n",
    "    X = Activation('relu', name=name_base + '1/relu_3')(X)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=name_base + '1/conv_3',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    ##### Branch2 ####\n",
    "    X_shortcut = BatchNormalization(axis=-1, name=name_base + '2/bn_1')(X_shortcut)\n",
    "    X_shortcut = Activation('relu', name=name_base + '2/relu_1')(X_shortcut)\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=name_base + '2/conv_1',\n",
    "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "\n",
    "    # Final step: Add Branch1 and Branch2\n",
    "    X = Add(name=base + '/Add')([X, X_shortcut])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def res_identity(X, filters, base):\n",
    "    name_base = base + '/branch'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    ##### Branch1 is the main path and Branch2 is the shortcut path #####\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### Branch1 #####\n",
    "    # First component of Branch1\n",
    "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_1')(X)\n",
    "    Shortcut = Activation('relu', name=name_base + '1/relu_1')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=name_base + '1/conv_1',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(Shortcut)\n",
    "\n",
    "    # Second component BranchOut 1\n",
    "    X1 = BatchNormalization(axis=-1, name=name_base + '1/ConvBn_2')(X)\n",
    "    X1 = Activation('relu', name=name_base + '1/ConvRelu_2')(X1)\n",
    "    X1 = Conv2D(filters=F2, kernel_size=(2, 2), dilation_rate=(2, 2), strides=(1, 1), padding='same',\n",
    "                name=name_base + '1/Conv_2', kernel_initializer=glorot_uniform(seed=0))(X1)\n",
    "\n",
    "    # Second component BrancOut 2\n",
    "    X2 = BatchNormalization(axis=-1, name=name_base + '1/SepBn_2')(X)\n",
    "    X2 = Activation('relu', name=name_base + '1/SepRelu_2')(X2)\n",
    "    X2 = SeparableConv2D(filters=F2, kernel_size=(2, 2), dilation_rate=(2, 2), strides=(1, 1), padding='same',\n",
    "                         name=name_base + '1/SepConv_2', kernel_initializer=glorot_uniform(seed=0))(X2)\n",
    "\n",
    "    # Second component Add-BranchOut\n",
    "    X = Add(name=base + '/Add-2branches')([X1, X2])\n",
    "\n",
    "    # Third component of Branch1\n",
    "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_3')(X)\n",
    "    X = Activation('relu', name=name_base + '1/relu_3')(X)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=name_base + '1/conv_3',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Final step: Add Branch1 and the original Input itself\n",
    "    X = Add(name=base + '/Add')([X_shortcut, X])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def EncoderDecoder(X, name_base):\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name=name_base + '/Downsample1')(X)\n",
    "    # X = Conv2D(outgoing_depth, (2,2), strides=(1,1), dilation_rate=(2,2), padding='same', name = name_base +\n",
    "    # '/DC1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = UpSampling2D(size=(2, 2), interpolation='bilinear', name=name_base + '/Upsample1')(X)\n",
    "    X = Activation('sigmoid', name=name_base + '/Activate')(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def RDBI(X, filters, base, number):\n",
    "    for i in range(number):\n",
    "        X = res_identity(X, filters, base + '/id_' + str(1 + i))\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def OpticNet(input_size, num_of_classes, strategy):\n",
    "    input_shape = (input_size, input_size, 3)  # Height x Width x Channel\n",
    "    X_input = Input(input_shape)\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='CONV1', kernel_initializer=glorot_uniform(seed=0))(\n",
    "        X_input)\n",
    "    X = BatchNormalization(axis=-1, name='BN1')(X)\n",
    "    X = Activation('relu', name='RELU1')(X)\n",
    "\n",
    "    X = res_conv(X, [64, 64, 256], 'RC0', 1)\n",
    "\n",
    "    # MID 1\n",
    "\n",
    "    X1 = EncoderDecoder(X, 'EncoderDecoder1')\n",
    "\n",
    "    X2 = RDBI(X, [32, 32, 256], 'RDBI1', 4)\n",
    "\n",
    "    X = Multiply(name='Mutiply1')([X1, X2])\n",
    "\n",
    "    X = Add(name='Add1')([X, X1, X2])\n",
    "\n",
    "    X = res_conv(X, [128, 128, 512], 'RC1', 2)\n",
    "\n",
    "    # MID 2\n",
    "\n",
    "    X1 = EncoderDecoder(X, 'EncoderDecoder2')\n",
    "\n",
    "    X2 = RDBI(X, [64, 64, 512], 'RDBI2', 4)\n",
    "\n",
    "    X = Multiply(name='Mutiply2')([X1, X2])\n",
    "\n",
    "    X = Add(name='Add2')([X, X1, X2])\n",
    "\n",
    "    X = res_conv(X, [256, 256, 1024], 'RC2', 2)\n",
    "\n",
    "    # MID 3\n",
    "\n",
    "    X1 = EncoderDecoder(X, 'EncoderDecoder3')\n",
    "\n",
    "    X2 = RDBI(X, [128, 128, 1024], 'RDBI3', 3)\n",
    "\n",
    "    X = Multiply(name='Mutiply3')([X1, X2])\n",
    "\n",
    "    X = Add(name='Add3')([X, X1, X2])\n",
    "\n",
    "    X = res_conv(X, [512, 512, 2048], 'RC3', 2)\n",
    "\n",
    "    # MID 4\n",
    "\n",
    "    X1 = EncoderDecoder(X, 'EncoderDecoder4')\n",
    "\n",
    "    X2 = RDBI(X, [256, 256, 2048], 'RDBI4', 3)\n",
    "\n",
    "    X = Multiply(name='Mutiply4')([X1, X2])\n",
    "\n",
    "    X = Add(name='Add4')([X, X1, X2])\n",
    "\n",
    "    X = GlobalAveragePooling2D(name='global_avg_pool')(X)\n",
    "    X = Dense(256, name='Dense_1')(X)\n",
    "    X = Dense(num_of_classes, name='Dense_2')(X)\n",
    "    X = Activation('softmax', name='classifier')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='')\n",
    "\n",
    "    model.compile(Adam(learning_rate=.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    modelo= OpticNet(input_size, num_of_classes, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from OpticNet.load_data import load_data\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    modelo.load_weights('efs2/Checkpoints OpticNet/OpticNet_OCT/cp.ckpt')\n",
    "    modelo.trainable=True\n",
    "    # Let's take a look to see how many layers are in the base model\n",
    "    print(\"Number of layers in the base model: \", len(model.layers))\n",
    "\n",
    "    # Fine-tune from this layer onwards\n",
    "    fine_tune_at = 274\n",
    "\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "    for layer in modelo.layers[:fine_tune_at]:\n",
    "        layer.trainable =  False\n",
    "    modelo.compile(Adam(lr=.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = modelo.fit(train_batches, \n",
    "                    shuffle=True,  \n",
    "                    validation_data=test_batches, \n",
    "                    epochs=5, \n",
    "                    verbose=1, \n",
    "                    callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    modelo.trainable=True\n",
    "    modelo.compile(Adam(lr=.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = modelo.fit(train_batches, \n",
    "                    shuffle=True,  \n",
    "                    validation_data=test_batches, \n",
    "                    epochs=5, \n",
    "                    verbose=1, \n",
    "                    callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "MN = os.listdir('efs/Checkpoints Mobilenet/Entrenamiento con OCT2017')\n",
    "XC = os.listdir('efs/Checkpoints Xception/Entrenamiento con OCT')\n",
    "RN = os.listdir('efs2/Checkpoints ResNet50/Entrenamiento con OCT')\n",
    "for file in MN:\n",
    "    src = 'efs/Checkpoints Mobilenet/Entrenamiento con OCT2017/'\n",
    "    dest =  'Modelos_TL/Entrenamiento con OCT/Mobilenet/Checkpoints/'\n",
    "    shutil.copy(src+file, dest+ file)\n",
    "    \n",
    "for file in XC:\n",
    "    src = 'efs/Checkpoints Xception/Entrenamiento con OCT/'\n",
    "    dest =  'Modelos_TL/Entrenamiento con OCT/Xception/Checkpoints/'\n",
    "    shutil.copy(src+file, dest+ file)\n",
    "    \n",
    "for file in RN:\n",
    "    src = 'efs2/Checkpoints ResNet50/Entrenamiento con OCT/'\n",
    "    dest =  'Modelos_TL/Entrenamiento con OCT/Resnet/Checkpoints/'\n",
    "    shutil.copy(src+file, dest+ file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_datas(base_dir, strategy):\n",
    "    BATCH_SIZE_PER_REPLICA = 16\n",
    "    batch_size = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "    val_dir = os.path.join(base_dir, 'val')\n",
    "    train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       rescale=1.0 / 255,\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode='nearest', \n",
    "                                       validation_split=0.1)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    classes = ['NORMAL', 'AR']\n",
    "    train_batches = train_datagen.flow_from_directory(train_dir,\n",
    "                                                      target_size=(160, 160),\n",
    "                                                      classes=classes,\n",
    "                                                      subset='training',\n",
    "                                                      shuffle=True,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      color_mode='rgb')\n",
    "    test_batches = test_datagen.flow_from_directory(test_dir,\n",
    "                                                    target_size=(160, 160),\n",
    "                                                    classes=classes,\n",
    "                                                    shuffle=True,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    color_mode='rgb')\n",
    "    val_batches = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   subset='validation',\n",
    "                                                   target_size=(160, 160),\n",
    "                                                   classes=classes,\n",
    "                                                   shuffle=True,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   color_mode='rgb')\n",
    "    return train_batches, test_batches, val_batches, classes\n",
    "\n",
    "train_batches, test_batches, val_batches, classes= load_datas(base_dir, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    model.trainable=True\n",
    "    model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Training the model\n",
    "batch_size=32\n",
    "history2 = model.fit(train_batches,\n",
    "                     shuffle=True,\n",
    "                     validation_data=val_batches,\n",
    "                     epochs=30,\n",
    "                     verbose=1,\n",
    "                     callbacks=cb,\n",
    "                     initial_epoch=18)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time) // 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Main_TL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
